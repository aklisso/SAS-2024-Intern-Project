{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python or R code based on the Language property.\n",
    "#\n",
    "# Note that a few lines of Python or R code are added before your code; for example:\n",
    "# Python:\n",
    "#  dm_class_input = [\"class_var_1\", \"class_var_2\"]\n",
    "#  dm_interval_input = [\"numeric_var_1\", \"numeric_var_2\"]\n",
    "# R:\n",
    "#  dm_class_input <- c(\"class_var_1\", \"class_var_2\")\n",
    "#  dm_interval_input <- c(\"numeric_var_1\", \"numeric_var_2\")\n",
    "#\n",
    "# For Python, use the Node Configuration section of the Project Settings to prepend\n",
    "# any configuration code, which is executed before the above code. During execution,\n",
    "# this code is automatically prepended to every node that runs Python code.\n",
    "#\n",
    "# After running the node, the Python or R code window in the node results displays\n",
    "# the actual code that was executed. START ENTERING YOUR CODE ON THE NEXT LINE.\n",
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Get full data with inputs + partition indicator\n",
    "dm_input.insert(0, dm_partitionvar)\n",
    "fullX = dm_inputdf.loc[:, dm_input]\n",
    "\n",
    "# Dummy encode class variables\n",
    "fullX_enc =  pd.get_dummies(fullX, columns=dm_class_input, drop_first=True)\n",
    "\n",
    "# Create X (features/inputs); drop partition indicator\n",
    "X_enc = fullX_enc[fullX_enc[dm_partitionvar] == dm_partition_train_val]\n",
    "X_enc = X_enc.drop(dm_partitionvar, axis=1)\n",
    "\n",
    "# Create y (labels)\n",
    "y = dm_traindf[dm_dec_target]\n",
    "\n",
    "#----------\n",
    "# Training\n",
    "#----------\n",
    "# Fit Random Forest model w/ training data\n",
    "dm_model = LogisticRegression(C = 0.7, random_state=42, solver='liblinear', class_weight='balanced')\n",
    "dm_model.fit(X_enc, y)\n",
    "print(dm_model)\n",
    "\n",
    "#----------\n",
    "# Scoring\n",
    "#----------\n",
    "# Score full data: posterior probabilities\n",
    "fullX_enc = fullX_enc.drop(dm_partitionvar, axis=1)\n",
    "dm_scoreddf_prob = pd.DataFrame(dm_model.predict_proba(fullX_enc),\n",
    "    columns=dm_predictionvar)\n",
    "\n",
    "# Score full data: class prediction\n",
    "dm_scoreddf_class = pd.DataFrame(dm_model.predict(fullX_enc),\n",
    "    columns=[dm_classtarget_intovar])\n",
    "\n",
    "# Column merge posterior probabilities and class prediction\n",
    "dm_scoreddf = pd.concat([dm_scoreddf_prob, dm_scoreddf_class], axis=1)\n",
    "print(dm_scoreddf.head(10))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
